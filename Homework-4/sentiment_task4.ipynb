{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 4: Sentiment Analysis - Task 4\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names & Sections\n",
    "----\n",
    "Names: __YOUR NAMES HERE__ (Write these in every notebook you submit. For each partner, write down whether you are a 4120 or a 6120 student.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Neural Networks (20 points)\n",
    "----\n",
    "\n",
    "Next, we'll train a feedforward neural net to work with this data. You'll train one neural net which takes the same input as your Logistic Regression model - a sparse vector representing documents as bags of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/davebudhram/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sentiment_utils as sutils\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# you can experiment with having some Dropout layers if you'd like to\n",
    "# this is not required\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# if you want to use this again\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants for the files we are using\n",
    "TRAIN_FILE = \"movie_reviews_train.txt\"\n",
    "DEV_FILE = \"movie_reviews_dev.txt\"\n",
    "\n",
    "# load in your data and make sure you understand the format\n",
    "# Do not print out too much so as to impede readability of your notebook\n",
    "X_train, y_train = sutils.generate_tuples_from_file(TRAIN_FILE)\n",
    "X_dev, y_dev = sutils.generate_tuples_from_file(DEV_FILE)\n",
    "\n",
    "# you may use either your sparse vectors or sklearn's CountVectorizer's sparse vectors\n",
    "# you will experiment with multinomial and binarized representations later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "22596\n"
     ]
    }
   ],
   "source": [
    "def convert2DArray(array):\n",
    "  result = []\n",
    "  for list in array:\n",
    "    list_text = \"\"\n",
    "    for word in list:\n",
    "      list_text += (word + \" \")\n",
    "    result.append(list_text)\n",
    "  return result\n",
    "\n",
    "X_train_strs = convert2DArray(X_train)\n",
    "X_dev_strs = convert2DArray(X_dev) \n",
    "count_vectorizer = CountVectorizer(binary=False)\n",
    "count_vectorizer.fit(X_train_strs)\n",
    "X_train_bow = count_vectorizer.transform(X_train_strs)\n",
    "X_dev_bow = count_vectorizer.transform(X_dev_strs)\n",
    "\n",
    "print(type(X_train_bow))\n",
    "# print(np.array(X_train_bow))\n",
    "print(len(count_vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 4)                 90388     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 90393 (353.10 KB)\n",
      "Trainable params: 90393 (353.10 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a feedforward neural network model\n",
    "# that takes a sparse BoW representation of the data as input\n",
    "# and makes a binary classification of positive/negative sentiment as output\n",
    "# you may use any number of hidden layers >= 1 and any number of units in each hidden layer (we recommend between 50-200)\n",
    "# you may use any activation function on the hidden layers \n",
    "# you should use a sigmoid activation function on the output layer\n",
    "# you should use binary cross-entropy as your loss function\n",
    "# sgd is an appropriate optimizer for this task\n",
    "# you should report accuracy as your metric\n",
    "# you may add Dropout layers if you'd like to\n",
    "\n",
    "# create/compile your model in this cell\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# hidden layer\n",
    "# you can play around with different activation functions\n",
    "model.add(Dense(units=4, activation='relu', input_dim=22596))\n",
    "\n",
    "\n",
    "\n",
    "# put in an output layer\n",
    "# activation function is our classification function\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "# call compile here\n",
    "\n",
    "# configure the learning process\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many trainable parameters does your model have? __YOUR ANSWER HERE__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.6653 - accuracy: 0.6037\n",
      "Epoch 2/3\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.6443 - accuracy: 0.6438\n",
      "Epoch 3/3\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5778 - accuracy: 0.7275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28775c6d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train your model\n",
    "# Felix's computer takes about 2 sec for 3 epochs\n",
    "# reports an accuracy of 0.78 at that point using the sgd optimizer\n",
    "\n",
    "# Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, (<class 'list'> containing values of types {\"<class 'int'>\"})\n",
    "# indicates you should change a list into a numpy array\n",
    "model.fit(X_train_bow, np.array(y_train), epochs=3, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 890us/step\n",
      "[1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# make a prediction on the dev set\n",
    "# then make a classification decision based on that prediction\n",
    "# predicting all examples takes < 1 sec on Felix's computer\n",
    "preds = model.predict(X_dev_bow)\n",
    "preds = [x[0] for x in preds]\n",
    "preds = [1 if x > .5 else 0 for x in preds]\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5941 - accuracy: 0.7100\n",
      "0.7099999785423279\n",
      "0.5940659642219543\n"
     ]
    }
   ],
   "source": [
    "# use the model.evaluate function to report the loss and accuracy on the dev set\n",
    "dev_loss, dev_accuracy = model.evaluate(X_dev_bow, np.array(y_dev), verbose=1)\n",
    "print(dev_accuracy)\n",
    "print(dev_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the same graph as with NB and LR, with your neural network model instead!\n",
    "# make sure to re-create your model each time you train it â€” you don't want to start with\n",
    "# an already trained network!\n",
    "\n",
    "# For a model with one hidden layer of 50 units:\n",
    "# Takes < 15 sec to run on Felix's computer w/ 3 epochs\n",
    "# Takes < 30 sec to run on Felix's computer w/ 10 epochs\n",
    "# Takes < 50 sec to run on Felix's computer w/ 20 epochs\n",
    "# you need not train your model more than 20 epochs\n",
    "# you should experiment with different numbers of epochs to see how performance varies\n",
    "# you need not create an experiment that takes > 10 min to run (please do not do this)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the f1 scores for your model with the following settings, using the same number of epochs to train in both cases:\n",
    "- number of epochs used: __YOUR ANSWER HERE__\n",
    "- multinomial features: __YOUR ANSWER HERE__ \n",
    "- binarized features: __YOUR ANSWER HERE__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
